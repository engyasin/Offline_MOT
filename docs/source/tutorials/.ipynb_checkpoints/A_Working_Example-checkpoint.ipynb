{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Working Example\n",
    "\n",
    "This example shows :\n",
    "\n",
    "1. how to run the program for some video\n",
    "\n",
    "2. how to set some important parameters for the detection, view fixing and post processing\n",
    "\n",
    "3. how to show the result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The detection part\n",
    "The detection part is separated by loading a pretrained YOLOv4 network. The training should be done separately before running the tracking program.\n",
    "\n",
    "The library that loads the structure of YOLO is part of the project (https://github.com/Tianxiaomo/pytorch-YOLOv4)\n",
    "\n",
    "Using other detection trained model is also possible, it just needs to be loaded within the class `YoloDetector` while changing the files directories in config file for the:\n",
    "\n",
    "1. The model directory\n",
    "2. The configuration file for Yolo network directory.\n",
    "3. The names of the classes in a new file with the extention ``.names``\n",
    "\n",
    "\n",
    "The training can be done in any library you want (tensorflow, Darknet). However, the result should be only in ``.pth`` format.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After installing the library simply by running:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting offlinemot\n",
      "  Downloading offlinemot-1.0.1.tar.gz (28.1 MB)\n",
      "     ---------------------------------------- 28.1/28.1 MB 5.0 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: numpy in c:\\users\\yasin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from offlinemot) (1.18.5)\n",
      "Requirement already satisfied: opencv-contrib-python in c:\\users\\yasin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from offlinemot) (4.5.3.56)\n",
      "Requirement already satisfied: scikit-image in c:\\users\\yasin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from offlinemot) (0.18.1)\n",
      "Requirement already satisfied: torch in c:\\users\\yasin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from offlinemot) (1.10.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\yasin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from offlinemot) (1.4.1)\n",
      "Requirement already satisfied: gdown in c:\\users\\yasin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from offlinemot) (4.3.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\yasin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from gdown->offlinemot) (4.62.3)\n",
      "Requirement already satisfied: requests[socks] in c:\\users\\yasin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from gdown->offlinemot) (2.25.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\yasin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from gdown->offlinemot) (3.6.0)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\yasin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from gdown->offlinemot) (4.8.1)\n",
      "Requirement already satisfied: six in c:\\users\\yasin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from gdown->offlinemot) (1.14.0)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in c:\\users\\yasin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from scikit-image->offlinemot) (2021.4.8)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in c:\\users\\yasin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from scikit-image->offlinemot) (1.1.1)\n",
      "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in c:\\users\\yasin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from scikit-image->offlinemot) (3.4.2)\n",
      "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,>=4.3.0 in c:\\users\\yasin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from scikit-image->offlinemot) (8.2.0)\n",
      "Requirement already satisfied: networkx>=2.0 in c:\\users\\yasin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from scikit-image->offlinemot) (2.5.1)\n",
      "Requirement already satisfied: imageio>=2.3.0 in c:\\users\\yasin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from scikit-image->offlinemot) (2.9.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\yasin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from torch->offlinemot) (3.10.0.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\yasin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->offlinemot) (0.10.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\yasin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->offlinemot) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\yasin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->offlinemot) (2.8.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\yasin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->offlinemot) (1.1.0)\n",
      "Requirement already satisfied: decorator<5,>=4.3 in c:\\users\\yasin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from networkx>=2.0->scikit-image->offlinemot) (4.4.1)\n",
      "Requirement already satisfied: soupsieve>=1.2 in c:\\users\\yasin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from beautifulsoup4->gdown->offlinemot) (1.9.5)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\yasin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from requests[socks]->gdown->offlinemot) (4.0.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\yasin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from requests[socks]->gdown->offlinemot) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\yasin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from requests[socks]->gdown->offlinemot) (1.26.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\yasin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from requests[socks]->gdown->offlinemot) (2020.12.5)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in c:\\users\\yasin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from requests[socks]->gdown->offlinemot) (1.7.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\yasin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from tqdm->gdown->offlinemot) (0.4.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\yasin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from kiwisolver>=1.0.1->matplotlib!=3.0.0,>=2.0.0->scikit-image->offlinemot) (59.5.0)\n",
      "Building wheels for collected packages: offlinemot\n",
      "  Building wheel for offlinemot (setup.py): started\n",
      "  Building wheel for offlinemot (setup.py): finished with status 'done'\n",
      "  Created wheel for offlinemot: filename=offlinemot-1.0.1-py3-none-any.whl size=28142813 sha256=706894498e37923dd31df9c5c3dd7ef74cff40d72495be1193436d7d81e7cb75\n",
      "  Stored in directory: c:\\users\\yasin\\appdata\\local\\pip\\cache\\wheels\\53\\b9\\a8\\e95b67a840f28f1b93c8a3e7f2da614fd729911ed05b9f151a\n",
      "Successfully built offlinemot\n",
      "Installing collected packages: offlinemot\n",
      "Successfully installed offlinemot-1.0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\yasin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\yasin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\yasin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\yasin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\yasin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\yasin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install offlinemot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1rhDaY7aVSeETP8rHgqZTewp4QkWlr3fb\n",
      "To: C:\\Users\\yasin\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\offlinemot\\model\\Yolov4_epoch300.pth\n",
      "100%|██████████| 256M/256M [00:43<00:00, 5.85MB/s] \n"
     ]
    }
   ],
   "source": [
    "import offlinemot\n",
    "from offlinemot.detection import YoloDetector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This class ``YoloDetector`` can take several input parameters, like the YOLO configuration file, the model file (in pytorch format), a flag to whether to use GPU or CPU and lastly a file containing the list of object names.\n",
    "\n",
    "If there's not a custom model to be loaded, then the default model can be loaded (as seen below).\n",
    "The example model will be downloaded when loading for the first time, this may take some time depending on your internet speed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convalution havn't activate linear\n",
      "convalution havn't activate linear\n",
      "convalution havn't activate linear\n"
     ]
    }
   ],
   "source": [
    "cfg = offlinemot.config.configs()\n",
    "detector  = YoloDetector(cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Detection is only performed every *N* frame. Where *N* is set according to `configs` class instance. In the following sections there is a detailed description of all its parameters and their effects.\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "\n",
    "**Note** \n",
    "\n",
    "A several testing with the parameters values maybe needed for different types of videos. Once a working set of values is found then all the similar videos can use the same set.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config file content\n",
    "\n",
    "To edit and show all these parameters, the following can be ran:\n",
    "\n",
    "```python\n",
    "import offlinemot\n",
    "cfg = offlinemot.config.configs()\n",
    "\n",
    "cfg['detect_every_N'] = 3 #changing some value\n",
    "\n",
    "cfg.print_summary() #showing the most important parameters and sections names\n",
    "\n",
    "cfg.print_section('Detection') # showing the detection parameters\n",
    "\n",
    "cfg.write('new.ini')\n",
    "```\n",
    "\n",
    "This will allow changes to all the parameters to be testsed and saved.\n",
    "\n",
    "\n",
    "\n",
    "### Detection and general configuration parameters\n",
    "\n",
    "Other paramters influencing the detection and the general settings are:\n",
    "\n",
    "```python\n",
    "    ### general parameters\n",
    "    draw = True\n",
    "    detect_every_N = 1\n",
    "    missing_thresh = 0.8\n",
    "    use_cuda = False\n",
    "    resize_scale = 0.4\n",
    "    colors_map = [ (0,255,0), # ped\n",
    "                   (255,0,0), # cyclist\n",
    "                   (0, 0, 0)] # cars\n",
    "    \n",
    "    ### Detection paramters\n",
    "    cwd = os.path.dirname(os.path.realpath(__file__))\n",
    "    model_name       = os.path.join(cwd,'model','Yolov4_epoch300.pth')\n",
    "    model_config     = os.path.join(cwd,'model','yolov4-obj.cfg')\n",
    "    classes_file_name= os.path.join(cwd,'model','obj.names')\n",
    "\n",
    "    detect_thresh = 0.3 #Yolo detection\n",
    "    # distance to the nearst match between detection and tracking\n",
    "    # output in pixels\n",
    "    dist_thresh = 25\n",
    "    size_thresh = 25\n",
    "    detect_scale = 4.0\n",
    "    \n",
    "```\n",
    "\n",
    "- The darwing flag `draw`, whether to draw or not.\n",
    "- With this variable:  `detect_every_N`, the number of detections frequency is determined. If high accuracy is needed then a value of 1 is optimal. Bigger values are less accurate but faster to run.\n",
    "- The `missing_thresh`parameter is for determining when to delete an object if it keeps failing tracking and detection, it should be between 0 and 1, with 0 means never delete, and 1 delete on the first failure. A value of 0.9 means delete if 10% of result is failed, keep otherwise.\n",
    "- The `use_cuda` flag is whether to use GPU for detection or CPU.\n",
    "- The `resize_scale` is just for display (if `draw` flag is True), to determine how much the image should be rescaled.\n",
    "- The `colors_map` list is for the color code for the different detection outputs. The first element correspond to the class with id=1 out of the Yolo network.\n",
    "\n",
    "\n",
    "- The `cwd` is the current directory of the config file\n",
    "- The `model_name` is for the trained model file directory\n",
    "- The `model_config` is for setting the parameters of the Yolo network, if a different structure is trained then a different file should be given here.\n",
    "- The `class_file_name` is a text file contining the names of the predicted classes from the detection network. \n",
    "- The `detect_thresh` is used to put a threshold on YOLO probabilty output for each detected class. The lower this value is the more detections it will give but with less accuracy. \n",
    "- The `dist_thresh` is for matching each detection with already detected object, it shouldn't be too big because it represents the minmum distance to match. Otherwise, false matching will be given.\n",
    "- The `size_thresh` is another distance but to the change in width and height between a detection and a nearby object. It is used because the same object from bird's eye view should have the same dimensions. \n",
    "- The `detect_scale` is for smaller objects detection. sometimes the drone is too high and the objects are small, so we need to *zoom in* to detect in a better way. one solution here is to detect in two levels: full scale image in the ordinary case and smaller proposed cropped areas. This parameter control how small these areas are. Higher values will make the areas bigger."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fixing and smoothing\n",
    "\n",
    "In `configs` class the following are the parameters for the part of fixing the view. The first boolean is for whether to do fixing or not. It will slow the processing, so if the video is stationary without noise then no need for it.\n",
    "\n",
    "```python\n",
    "### fix view paramers\n",
    "do_fix = False\n",
    "fixing_dilation = 13\n",
    "min_matches     = 15\n",
    "```\n",
    "\n",
    "The part for doing the smoothing is also included in the same file as follows. The first boolean is whether to do the smoothing or not, the other two are related to Savitzky-Golay filter from `scipy` library.\n",
    "\n",
    "The last boolean flag `save_out_video` will save a new mp4 file in the same folder as the video with the same name started with *output_* if set to True. This will be run only with `offlinemot.show_results.show_result()`\n",
    "\n",
    "```python\n",
    "### Smoothing for post processing\n",
    "do_smooth   = True\n",
    "window_size = 7\n",
    "polydegree  = 3\n",
    "save_out_video = False\n",
    "```\n",
    "\n",
    "Other steps (along with smoothing) are included in the `postprocess.py` file, namely, the orientation calculation and interpolation of missing positions in the tracks. The orientation is calculated from the trajectory itself where the next point in the trajectory determines the current point heading."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Background subtraction parameters\n",
    "\n",
    "Many parmeters are avaliable for background subtraction, as follows,\n",
    "\n",
    "```python\n",
    "\n",
    "    ### background subtractor parameters\n",
    "    bgs_history = 5\n",
    "    bgs_threshold = 50\n",
    "    bgs_shadows = True\n",
    "    bgs_learning = 0.5\n",
    "    bgs_erosion_size = 3\n",
    "    bgs_min_area = 300\n",
    "    bgs_broder_margin =  0.45    # bigger would give boxes near the detected boxes with yolo\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "The most important of them are:\n",
    "\n",
    "- The `bgs_history` determines how many frames are used to calculate the background\n",
    "\n",
    "- The `bgs_threshold` is realted to the sensativaty of the subtraction , lower values will give more sensativity to movements\n",
    "\n",
    "- The `bgs_erosion_size` is the síze of the mask to perform erosion on the forground. higher values will give thiner objects\n",
    "\n",
    "- The `bgs_min_area` determines the minmum area of pixels that will be considered as object, otherwise it will be deleted.\n",
    "\n",
    "- THe `bgs_broder_margin` determines how mush overlapping is allowed between already detected objects and newly found forground. this number is considered a percentage of the detected object dimensions that objects are allowed to be in. For example a value of 0.5 will mean everywhere is allowed, because half of the dimension on all the objects means all the objects' area.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filering parameters\n",
    "\n",
    "Additionally, in the `configs` class, there's parameters that will determine when to delete the detected objects.\n",
    "\n",
    "```python\n",
    "\n",
    "    ### Filtering Objects:\n",
    "    min_history = 100\n",
    "    overlap_thresh = 0.7\n",
    "```\n",
    "\n",
    "- The `min_hisory` is the minmum number of frames that the objects will start to be tested for percentage of correct tracking (with `missing_thresh`).\n",
    "\n",
    "- The `overlap_thresh` is for the minmum area percentage of overlapping between confirmed objects to delete one of them.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to run\n",
    "\n",
    "To run for a new video, after setting the parameters, the command will be:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convalution havn't activate linear\n",
      "convalution havn't activate linear\n",
      "convalution havn't activate linear\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Some objects are detected but not moving or seen before\n",
      "WARNING:root:Some objects are detected but not moving or seen before\n",
      "WARNING:root:Some objects are detected but not moving or seen before\n"
     ]
    }
   ],
   "source": [
    "offlinemot.core.extract_paths()# input your video path here (empty means the example video)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and so on..\n",
    "\n",
    "To stop the program at any point, simply press **ESC**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to show result\n",
    "\n",
    "After running the program on your video, a text file will be saved in same directory as the inputed video with the same name as well.\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "**Warning** \n",
    "\n",
    "if there's any text file with the same name of the video, then it will be overwritten without warning\n",
    "</div>\n",
    "\n",
    "\n",
    "If you want to show the result with angles and smoothing for the sample video above, you can run the command: \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import offlinemot\n",
    "offlinemot.show_results.show_result(None,config=cfg)#put path of the video here (including extention, ex mp4, avi ..)\n",
    "# None for the sample video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After running this command with your video path and extention (empty for an example), a new video will be written, if that is set in `cfg` class, annotated with the tracked objects. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output structure\n",
    "\n",
    "in the output text file, each line is structured as follows,\n",
    "\n",
    "*Frame_id* &nbsp; \\[ top_left_x &nbsp; top_left_y &nbsp; width &nbsp; height\\] &nbsp; *class_id* &nbsp; *track_id* &nbsp; *angel*\n",
    "\n",
    "´39 &nbsp; [3748, &nbsp; 964, &nbsp; 169, &nbsp; 73] &nbsp; 2  &nbsp; 5 &nbsp; 138´\n",
    "\n",
    "Above is an example of one line.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
